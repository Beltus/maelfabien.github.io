---
published: true
title: Discover Spark-Scala
collection: bgd
layout: single
author_profile: false
read_time: true
categories: [bigdata]
excerpt : "Parallel and Distributed Computing"
header :
    overlay_image: "https://maelfabien.github.io/assets/images/wolf.jpg"
    teaser: "https://maelfabien.github.io/assets/images/wolf.jpg"
comments : true
toc: true
toc_sticky: true
sidebar:
    nav: sidebar-sample
---

As we discussed before, Spark-Scala API is the most widely used API and is a production-ready solution.

![image](https://maelfabien.github.io/assets/images/Scala.jpg)

# What is Scala?

Scala is a functional programming language. It is a powerful programming concept that offers more robustness than imperative or object programming. Scala is not purely functional but would rather be in a grey area between the two.

One of the main feature of Scala is the the function compostion :

```scala
val validUrls: DataFrame = dfInitial
.select("cleanUrls","tags")
.dropDuplicates
.groupBy("cleanUrls")
.count
.filter(col("count")===1)
.select("cleanUrls")
```

In this example, every function (groupBy, dropDuplicates...) is applied to the data frame before the dot, and each function returns a new data frame.

Disclaimer: This tutorial was working properly at the end of 2018. The versions I'm using in this article might not be available anymore.


## Using Scala



> Conclusion: I hope this first approach to Spark-Scala was clear and helpful. I'd be happy to answer any question you might have in the comments section.