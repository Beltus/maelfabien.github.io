---
published: true
title: Convolutional Neural Networks
collection: dl
layout: single
author_profile: false
read_time: true
categories: [deeplearning]
excerpt : "Deep Neural Networks"
header :
    overlay_image: "https://maelfabien.github.io/assets/images/wolf.jpg"
    teaser: "https://maelfabien.github.io/assets/images/wolf.jpg"
comments : true
toc: true
toc_sticky: true
sidebar:
    nav: sidebar-sample
---

Convolutional Neural Network (CNN) are feed-forward neural network that are mostly used for computer vision or time series analysis. They offer an automated image pre-treatment as well as a dense neural network part. CNNs are special types of neural networks for processing data with grid-like topology. The architecture of the CNN is inspired by the visual cortex of animals.

<script type="text/javascript" async
    src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

# What is a CNN ?

## Filters

![image](https://maelfabien.github.io/assets/images/CNN.jpg)

The main idea behind using CNNs is to extract more information than the pixel value itself. Indeed, individual pixel values do not bring a lot of information. For this reason, we apply filters on the images. Historically, a great part of the work was to select these filters manually (e.g Gabor filters) and an architecture of the filters in order to extract as much information from the image as possible. The aim of these filters was for example to extract :
- edges
- contrast zones
- dark or light zones
- ...

How can we extract information from a filter ? Well, you should see a filter as a sliding window that creates an operation locally, between all the pixels located in a region. Therefore, we can extract more information than a single pixel value. If you're interested in this, check my articles on computer vision and filtering.

## Automatic image processing 

With the rise of deep learning and greater computation capacities, this work can now be automated. The name of the Convolutional Neural Networks comes from the fact that we convolve the initial image input with a set of filters. This time, we don't have to select the filters anymore. The parameter to choose remain :
- the number of filters to apply, 
- the dimension of the filters
- the step size with which we convolve the filter with the image
- the padding

The **dimension** of the filter is called the kernel size. Typical values for the stride lie between 2 and 5. For example, on an image of size $$ 100 \times 100 $$, we can apply a filter of size 5.

## INSERT IMAGE

The **step size** is simply the amount by which we shift the filter at each step. 

## INSERT IMAGE

When we convolve a filter with an image, we'll reach the end of the row of pixels at some point. There are two approaches in this case :
- either we stop when the extremity of the filter reaches the boundary of the image. This is called : `padding='valid'` in Keras for example. In this case, we lose a bit of the dimension of the image.
- otherwise, we convolve the image with the objective to keep the original dimension. This is called : `padding='same'` in Keras.

## INSERT IMAGE

By adding several filters, we convolve the image with filters many times. In some sense, we are building a convolved output that has a volume. It's no longer a 2 dimensional picture. The filters end up being hardly humanly understandable, especially when we use a lot of them. Some are used to find curves, other edges, other textures... 

## A bit of maths

Mathematically, the convolution is expressed as such :
$$ (f * g)(t) = \int_{-\infty}^{+\infty} f(\tau)g(t-\tau) \partial \tau $$

The convolution represents the percentage of area of the filter \(g\) that overlaps with the input $$ f $$ at time $$ \tau $$ over all time $$ t $$ . However, since $$ \tau < 0 $$ and $$ \tau > t $$ have no meaning, the convolution is described as :

$$ (f * g)(t) = \int_{0}^{t} f(\tau)g(t-\tau) \partial \tau $$

At each convolution step, for each input, we apply an activation function (usually ReLU). So far, we have only added dimensionality to our initial image input. We then apply a so-called pooling. Pooling involves a down sampling of features so that we need to learn less parameters when training. The most common form of pooling is max-pooling. For each of the dimension of each of the input image, we perform a max-pooling that takes, over a given height and width, typically 2x2, the maximum value among the 4 pixels. The intuition is that the maximal value has higher chances to be more significant when classifying an image. 

We have now covered all the ingredients of a convolution neural network :
- the convolution layer
- the activation
- the pooling layer
- the fully connected layer, similar to a dense neural network

The order of the layers can be switched :

$$ ReLU(MaxPool(Conv(X))) = MaxPool(ReLU(Conv(X))) $$

In image classification, we usually add several layers of convolution and pooling. This allows us to model more complex structures. Most of the model tuning in deep learning is to determine the optimal model structure. Some famous algorithms developed by Microsoft or Google reach a depth of more than 150 hidden layers. 

# Implementing CNNs in Keras

Implementing a CNN in Keras can be done the following way :

```python
def createModel():

    model = Sequential() 

    model.add(Conv2D(32, (3, 3), padding='same', activation='relu', 
    input_shape=input_shape))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(BatchNormalization())

    model.add(Conv2D(32, (3, 3), activation='relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(BatchNormalization())

    model.add(Conv2D(32, (3, 3), padding='same', activation='relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))

    model.add(Conv2D(32, (3, 3), padding='same', activation='relu'))

    model.add(Flatten())
    model.add(Dense(512, activation='relu'))
    model.add(Dense(nClasses, activation='softmax'))

    return model
```

As you can see, we add several convolution, max pooling and batch normalization layers, before flattening the output of the layers and adding several dense layers. The final dense layer here contains the number of classes we are working with in the inputs.

# Implementing CNNs in PyTorch



> **Conclusion** : CNNs are nowadays key elements in computer vision. I have recently been working on a facial emotion recognition algorithm. The structure of the model implemented is very similar to the one exposed above.
