---
published: true
title: Anomaly Detection
collection: st
layout: single
author_profile: false
read_time: true
categories: [machinelearning]
excerpt : "Supervised Learning Algorithms"
header :
    overlay_image: "https://maelfabien.github.io/assets/images/wolf.jpg"
    teaser: "https://maelfabien.github.io/assets/images/wolf.jpg"
comments : true
toc: true
toc_sticky: true
sidebar:
    nav: sidebar-sample
---

> “An anomaly is an observation that deviates so much from other observations as to arouse suspicions that it was generated by a different mechanism.", Hawkins (1980)

Anomaly detection is used in :
- network intrusions
- creit card fraud detection
- insurance
- finance
- surveillance
- rental services
- ...

There are 3 types of anomaly detection :
- supervised : we have labels for both normal data and anomalies
- semi-supervised : only normal data is available, no outliers are present
- unsupervised : no labels, we suppose that anomalies are rare events

The key steps in anomaly detection are the following :
- learn a profile of a normal behavior, e.g. patterns, summary statistics...
- use that normal profile to build a decision function
- detect anomalies among new observations

# Supervised Anomaly Detection

In the supervised Setup, we have pairs of data $$ (X,Y) $$ values in $$ R^d \times \{-1,+1\} $$. If a data point has a positive label (Y=1), it is an anomaly. This is a classic binary classification task. 

We also define a randking among anomalies, with the first data points the ones that have the highest probability to be anomalies. This is called *Bipartite Ranking*. It is a different approach from classification, since classification remains a local task, whereas ranking is global.

We rank and score a set of instances through a scoring function $$ s(X) $$ in which large number instances with label 1 appear on top of the list with high probabilities.

How do we measure the quality of a ranking?

A natural estimate of the ranking performance : 

$$ U(s) = P \{ (s(X) -s(X'))(Y-Y')>0\} $$

is the U-Statistic :

$$ Û_n(s) = \frac{2}{n(n-1)} \sum_{1≤i<j≤n}1\{(s(X_i) - s(X_j))(Y_i - Y_j) > 0} $$

This measure is also called the **rate of concording pairs**, or **Kendall's association coefficient**. One of the issues is that the computation of the gradients typically require to average over $$ O(n^2) $$ pairs. 

The criterion we want to maximize is :

$$ L(s) = P \{s(X^{(1)}) < \cdots < s(X^{(k)}) \mid Y^{(1)} = 1, \cdots, Y^{(k)} = K \} $$

The empirical counterpart of $$ L(s) $$ is really prohibitive to compute, and the maximization is even unfeasible. To overcome such issues, generalized U-Statistics using Kernels or incomplete U-Statistics using only a sample of terms can be used.

# Unsupervised Anomaly Detection

In unsupervised anomaly detection, we make the assumption that anomalies are rare events. The underlying data are unlabeled (no normal/abnormal label), hence the denomination. Anomalies are events supposed to be locates in the tail of the distribution.

We usually estimate the region where the data is the most concentrated as the minimal region containing $$ \alpha % $$ of the values. This approach is called **Minimum Volume Set**. The closer we bring $$ \alpha $$ to 1, the more likely we are to detect anomalies. For a small value of $$ \alpha $$ on the other hand, we tend to recover the modes.





![image](https://maelfabien.github.io/assets/images/kernel_trick.jpg)
