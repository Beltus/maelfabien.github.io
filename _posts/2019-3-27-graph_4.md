---
published: true
title: Graph Learning
collection: st
layout: single
author_profile: false
read_time: true
categories: [machinelearning]
excerpt : "Graph Analysis and Graph Learning"
header :
    overlay_image: "https://maelfabien.github.io/assets/images/wolf.jpg"
    teaser: "https://maelfabien.github.io/assets/images/wolf.jpg"
comments : true
toc: true
toc_sticky: true
---

So far, we covered the main kind of graphs, and the basics of graph analysis. We'll now cover into more details the way we can "learn" in graphs.

<script type="text/javascript" async
    src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

{% highlight python %}
{% endhighlight %}

For what comes next, open a Jupyter Notebook and import the following packages :

```python
import numpy as np
import random
import networkx as nx
from IPython.display import Image
import matplotlib.pyplot as plt
```

If you have not already installed the `networkx` paxkage, simply run :

```bash
pip install networkx
```

The following articles will be using the latest version  `2.x` of  `networkx`. NetworkX is a Python package for the creation, manipulation, and study of the structure, dynamics, and functions of complex networks.

To illustrate the different concepts we'll cover and how it applies to graphs we'll take the Karate Club example. This graph is present in the `networkx` package. It represents the relations of members of a Karate Club. However, due to a lack a agreement of the founders of the club, the club has recently been splitted in two. We'll try to illustrate this event with graphs. 

First, load and plot the graph :

```python
n=34
m = 78
G_karate = nx.karate_club_graph()

pos = nx.spring_layout(G_karate)
nx.draw(G_karate, cmap = plt.get_cmap('rainbow'), with_labels=True, pos=pos)
```

![image](https://maelfabien.github.io/assets/images/karate.png)

# I. What is Graph Learning ?

There are two main tasks in graph learning :
- link prediction
- node labelling

We'll start off with link prediction.

## Link prediction

In Link Prediction, given a graph $$ G $$, we aim to predict new edges. Predictions are useful to predict future relations or missing edges when the graph is not fully observed for example. 

In link prediction, we simply try to build a similarity measure between pairs of nodes, and link the most similar (up to a threshold $$ k $$ for example). The question is now to identify the right similarity scores !

To illustrate the different similarity scores, let's consider the following graph :

![image](https://maelfabien.github.io/assets/images/graph_13.png)

Let $$ N(i) $$ be a set of neighbors of node $$ i $$. On the graph above, the neighbors of both nodes $$ i $$ and $$ j $$ can be represented as :

![image](https://maelfabien.github.io/assets/images/graph_15.png)

![image](https://maelfabien.github.io/assets/images/graph_16.png)

We can build several similarity scores :
- Common Neigbbors : $$ S(i,j) = \mid N(i) \cap N(j) \mid $$. In this example, the score would be simply 1.

![image](https://maelfabien.github.io/assets/images/graph_17.png)

- Jaccard Coefficient : $$ S(i,j) = \frac { \mid N(i) \cap N(j) \mid } { \mid N(i) \cup N(j) \mid } $$. This is a normalized common neighbors version.

The intersection is the Common Neighbors, and the union is :

![image](https://maelfabien.github.io/assets/images/graph_18.png)

Therefore, the Jaccard Coefficient is given by the ratio :

![image](https://maelfabien.github.io/assets/images/graph_19.png)

And the value is $$ \frac {1} {6} $$.
- Adamic-Adar index : $$ S(i,j) = \sum_{k \in N(i)\cap N(j) } \frac {1}Â {\log \mid N(k) \mid} $$
In other words, for each common neigbbor of nodes $$ i $$ and $$ j $$, sum $$ 1 $$ divided by the total number of neighbors of that node. The concept is that common elements with very large neighbourhoods are less significant when predicting a connection between two nodes compared with elements shared between a small number of nodes.
- Preferential attachement : $$ S(i,j) = \mid N(i,j) \mid * \mid N(j) \mid $$
- We can also use the community information when it is available.

How do we perform the evaluation of the link prediction ?
We must hide a subset of node pairs, and predict their links based on the rules defined above. We then evaluate the proportion or correct predictions for dense graphs, or use Area under the Curve criteria for Sparse graphs.

Let's implement this in Python on our Karate graph !

First of all, print the information of the graph :

```python
n = G_karate.number_of_nodes()
m = G_karate.number_of_edges()
print("Number of nodes : %d" % n)
print("Number of edges : %d" % m)
print("Number of connected components : %d" % nx.number_connected_components(G_karate))
```

Then, plot the graph itself :

```python
plt.figure(figsize=(12,8))
nx.draw(G_karate)
plt.gca().collections[0].set_edgecolor("#000000")
```

![image](https://maelfabien.github.io/assets/images/graph_20.png)

Now, let's remove some connections :

```python
# Remove 20% of the edges
proportion_edges = 0.2
edge_subset = random.sample(G_karate.edges(), int(proportion_edges * G_karate.number_of_edges()))

# Create a copy of the graph and remove the edges
G_karate_train = G_karate.copy()
G_karate_train.remove_edges_from(edge_subset)
```

And plot the partially observed graph !:

```python
plt.figure(figsize=(12,8))
nx.draw(G_karate_train)
plt.gca().collections[0].set_edgecolor("#000000") # set node border color to black
```

![image](https://maelfabien.github.io/assets/images/graph_21.png)

You can print the number of edges we deleted and the number of edges remaining :

```python
edge_subset_size = len(list(edge_subset))
print("Number of edges deleted : %d" % edge_subset_size)
print("Number of edges remaining : %d" % (m - edge_subset_size))
```

```
Number of edges deleted : 15
Number of edges remaining : 63
```

### Jaccard Coefficient

```python
# Make prediction using Jaccard Coefficient
pred_jaccard = list(nx.jaccard_coefficient(G_karate_train))
score_jaccard, label_jaccard = zip(*[(s, (u,v) in edge_subset) for (u,v,s) in pred_jaccard])
```

The prediction look like this, a first node, a second node and a jaccard score :

```
[(0, 32, 0.15),
(0, 33, 0.125),
(0, 3, 0.21428571428571427),
(0, 9, 0.0),
(0, 14, 0.0),
(0, 15, 0.0),
...
```

Then, compute the score :

```python
# Compute the ROC AUC Score
fpr_jaccard, tpr_jaccard, _ = roc_curve(label_jaccard, score_jaccard)
auc_jaccard = roc_auc_score(label_jaccard, score_jaccard)
```

### Adamic-Adar

We can now repeat this for the Adamic-Adar Index :

```python
# Prediction using Adamic Adar 
pred_adamic = list(nx.adamic_adar_index(G_karate_train))
score_adamic, label_adamic = zip(*[(s, (u,v) in edge_subset) for (u,v,s) in pred_adamic])

# Compute the ROC AUC Score
fpr_adamic, tpr_adamic, _ = roc_curve(label_adamic, score_adamic)
auc_adamic = roc_auc_score(label_adamic, score_adamic)
```

### Preferential Attachment

And for the preferential attachment score :

```python
# Compute the Preferential Attachment
pred_pref = list(nx.preferential_attachment(G_karate_train))
score_pref, label_pref = zip(*[(s, (u,v) in edge_subset) for (u,v,s) in pred_pref])

fpr_pref, tpr_pref, _ = roc_curve(label_pref, score_pref)
auc_pref = roc_auc_score(label_pref, score_pref)
```

### Plot the ROC AUC Curve

The Adamic-Adar seems to outperform the other criterias on our problem :

![image](https://maelfabien.github.io/assets/images/graph_22.png)

We covered the most common similarity scores for link prediction. We'll now cover into more details the node labeling algorithms.

# Node Labeling

Given a graph where some nodes are not labeled, we want to predict their labels. This is in some sense a semi-supervised learning problem.

One common way to deal with such problems is to make the assumption that there is a certain smoothness on the graph. The Smoothness assumption states that points connected via a path through high density regions on the data are likely to have similar labels. This is the main hypothesis behind the Label Propagation Algorithm. 

The Label Propagation Algorithm (LPA) is a fast algorithm for finding communities in a graph using network structure alone as its guide, without any predefined objective function or prior information about the communities.

![image](https://maelfabien.github.io/assets/images/lpa.png)

A single label can quickly become dominant in a densely connected group of nodes, but it will have trouble crossing a sparsely connected region. 

How does the semi-supervised label propagation work ?

First, we have some data : $$ x_1, ..., x_l, x_{l+1}, ..., x_n \in R^p $$, and labels for the first $$ l $$ points : $$ y_1, ..., y_l \in 1...C $$

We define the initial label matrix $$ Y \in R^{n \times C} $$ such that $$ Y_{ij} = 1 $$ if $$ x_i $$ has label $$ y_i = j $$ and $$ 0 $$ otherwise. 



> **Conclusion** : I hope that this article on graph learning was helpful. Don't hesitate to drop a comment if you have any question.

Sources : 
- *A Comprehensive Guide to Graph Algorithms in Neo4j*
- Networkx Documentation
