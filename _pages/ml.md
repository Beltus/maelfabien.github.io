---
layout: single
permalink: /ml/
author_profile: true
header :
    image: "https://maelfabien.github.io/assets/images/ml_head.png"
toc: true
toc_sticky: true
---

A series of articles dedicated to machine learning.

## Machine Learning Basics

[Basics and Motivation](https://maelfabien.github.io/machinelearning/ml_base/) : A first approach to machine learning. We'll go over the main motivations, the main kind of algorithms, what they can be used for...

[Supervised Learning Cheat Sheet](https://maelfabien.github.io/machinelearning/supervised/) : A cheat sheet that recaps the main supervised learning algorithms. It includes an illustration, and the minimization problem for each of them.

[Unsupervised Learning Cheat Sheet](https://maelfabien.github.io/machinelearning/unsupervised/) : A cheat sheet that recaps the main unsupervised learning algorithms. It includes an illustration, and the minimization problem for each of them.

## Supervised Learning Algorithms

[Bayes Classifier](https://maelfabien.github.io/machinelearning/bayes/) : At the core of any algorithm, the Bayes Classifier is considered as one of the first algorithm to master.

[Linear Discriminant Analysis](https://maelfabien.github.io/machinelearning/LDA/) : In this article, we'll cover the intuition behind LDA, when it should be used, and the maths behind it.

[Adaptative Boosting (AdaBoost)](https://maelfabien.github.io/machinelearning/adaboost/) : A clear approach of boosting algorithms and adaptative boosting with illustrations. When should we use boosting ? What are the foundations of the algorithm ?

[Large Scale Kernel Methods](https://maelfabien.github.io/machinelearning/largescale/) : Kernel methods offer a great way to solve complex problems. However, it gets computationally hard to implement them at scale. This is being solved by Large Scale Kernel methods.

## Natural Language Processing

[Text Preprocessing](https://maelfabien.github.io/machinelearning/NLP_1/) : Preprocessing in Natural Language Processing (NLP) is the process by which we try to "standardize" the text we want to analyze.

[Text Embedding with Bag-Of-Words and TF-IDF](https://maelfabien.github.io/machinelearning/NLP_2/) : In order to analyze text and run algorithms on it, we need to embed the text. The notion of embedding simply means that we'll conver the input text into a set of numerical vectors that can be used into algorithms. In this article, we'll cover BOW and TF-IDF, two simple techniques for embedding.

[Text Embedding with Word2Vec](https://maelfabien.github.io/machinelearning/NLP_3/) : A deeper dive into the state of the art embedding technique : Word2Vec.

## Hidden Markov Models and Markov Chains

[Markov Chains](https://maelfabien.github.io/machinelearning/HMM_1/) : Markov Chains are the basic building block for Hidden Markov Models, widely used in image processing or in NLP.

## Graph Analysis and Graph Learning

[Introduction to Graphs](https://maelfabien.github.io/machinelearning/graph_1/) : What is a graph ? Where are graphs being used ? What are the components of a graph ?

[Graph Analysis, Erdos-RÃ©nyi, Barabasi-Albert](https://maelfabien.github.io/machinelearning/graph_2/) : In this article, we cover the two main types of graphs, and describe a first approach to graph analysis. 

[Graph Algorithms](https://maelfabien.github.io/machinelearning/graph_3/) : We'll now explore the main graph algorithms and several use cases in a visual way with direct examples in Python. 

[Graph Learning](https://maelfabien.github.io/machinelearning/graph_4/) : How can we handle missing links or missing nodes in graphs ? 

## Parameters Optimization

Articles to come (Grid Search, Random Search, Bayesian Hyperopt...)

## Metrics in Machine Learning

Articles to come (Imbalanced Data, ...)

